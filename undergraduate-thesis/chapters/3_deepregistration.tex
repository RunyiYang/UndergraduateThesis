\chapter{基于深度学习的点云配准}
本章将结合深度学习，对点云配准进行研究。首先介绍深度学习中点云配准常用的公开数据集，然后介绍点云配准的评价指标并推广到多实例点云配准，最后介绍点云配准相关的深度学习技术。

\section{标准数据集}
本节将介绍用于点云配准的标准数据集。在评估不同指标的性能时，我们需要用到不同的公开数据集。点云配准任务的数据集大致可以分为仿真数据集和真实数据集。仿真数据集中的物体对象是完整的三维模型，比如ModelNet40\cite{sunmodelnet40}。而真实数据集中，因为存在遮挡、测量误差、相干光干扰、背景影响等问题，往往会存在缺失、噪声、过密/稀疏等问题，比如Scan2CAD\cite{avetisyan2019scan2cad}和ShapeNet\cite{chang2015shapenet}。下表\ref{tab:PointCloudDatasets}列出了常用的点云配准数据集。
\begin{table}[h!]
    \centering
    \vspace{-1.0cm}
    \caption{常见的点云信息处理任务数据集列表}
    \label{tab:PointCloudDatasets}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{|l|c|c|c|c|c|c|c|}
    \hline
    \textbf{数据集名称} & \textbf{年份} & \textbf{场景数量} & \textbf{类别数量} & \textbf{训练集} & \textbf{测试集} & \textbf{类型} & \textbf{数据结构} \\ \hline
    McGill Benchmark \cite{siddiqi2008retrieving} & 2008 & 456 & 19 & 304 & 152 & 仿真场景 & 三角网格 \\ \hline
    Sydney Urban Objects \cite{de2013unsupervised} & 2013 & 588 & 14 & - & - & 真实场景 & 点云 \\ \hline
    ModelNet10 \cite{wu20153d} & 2015 & 4899 & 10 & 3991 & 605 & 仿真场景 & 三角网格 \\ \hline
    ModelNet40 \cite{sunmodelnet40} & 2015 & 12311 & 40 & 9843 & 2468 & 仿真场景 & 三角网格 \\ \hline
    ShapeNet \cite{chang2015shapenet} & 2015 & 51190 & 55 & - & - & 仿真场景 & 三角网格 \\ \hline
    ScanNet \cite{dai2017scannet} & 2017 & 12283 & 17 & 9677 & 2606 & 真实场景 & RGB-D \\ \hline
    ScanObjectNN \cite{uy2019revisiting} & 2016 & 2902 & 15 & 2321 & 581 & 真实场景 & 三角网格 \\ \hline
    S3DIS \cite{armeni20163d} & 2017 & 271 & 13 & - & - & 真实场景 & 点云 \\ \hline
    7Scenes \cite{shotton2013scene} & 2013 & 7 & 1 & 26000 & 17000 & 真实场景 & RGB-D \\ \hline
    Scan2CAD \cite{avetisyan2019scan2cad} & 2019 & 1512 & 1 & 1209 & 303 & 真实场景 & 点云 \\ \hline
    \end{tabular}
    }
    \vspace{-1.0cm}
\end{table}

在本次任务中，我们使用ModelNet40、ShapeNet、Scan2CAD组成多实例点云配准仿真数据集进行训练和测试。所以，我们对这三个数据集和多实例点云配准数据集进行了详细的介绍。

\subsection{ModelNet40}
ModelNet 是一个用于三维物体识别和检索的大规模数据集。它包含两个子集：ModelNet10 和 ModelNet40。ModelNet10 包含 10 个类别的 4,899 个模型，而 ModelNet40 包含 40 个类别的 12,311 个模型。ModelNet 数据集中的模型主要是合成的 CAD 模型，并以网格 (mesh) 的形式呈现。本文主要使用 ModelNet40 数据集。 

ModelNet40 主要涵盖了各种常见物体，如办公桌、椅子、沙发、书架、飞机、自行车、花盆等。其中例如杯子、桌子、飞机等这种具有规则对称结构的模型，对于位姿回归、点云配准来说是比较困难的，容易因为对称轴而产生歧义。对于人、花这样具有复杂结构的模型，也很难准确识别模型的关键信息，在点云处理中具有一定的挑战性。ModelNet40 数据集部分可视化结果如图 \ref{fig:modelnet}所示。

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{images/ModelNet.pdf}
    \caption{ModelNet40 数据集部分可视化结果}
    \label{fig:modelnet}
    \vspace{-0.5cm}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{images/Shapenet-Scan2CAD.pdf}
    \caption{ShapeNet 数据集和Scan2CAD 数据集部分可视化结果}
    \label{fig:ShapeNet&Scan2CAD}
    \vspace{-0.5cm}
\end{figure}
\subsection{ShapeNet}
ShapeNet 数据集是一个大规模的三维模型数据库，其目的是为计算机视觉和图形学领域的研究者提供一个丰富且多样化的数据源。该数据集涵盖了许多不同的物体类别，包括家具、交通工具、家电等。ShapeNet 数据集中的模型具有详细的几何形状和丰富的语义标注，这使得它在多种三维任务中都具有很高的实用价值。

ShapeNet 数据集包含了 55 个类别，共有 51,190 个三维模型。这些模型主要来源于网上的 CAD 模型库，经过清洗和处理后整合成一个统一的数据集。数据集中的每个模型都以网格（mesh）格式存储，并附有与物体相关的语义信息，如类别标签、实例标签等。此外，ShapeNet 数据集还包含了一些额外的元数据，如模型的尺寸、位置和方向等。部分可视化结果如图\ref{fig:ShapeNet&Scan2CAD} (a) 所示。

\subsection{Scan2CAD}
Scan2CAD 数据集是一个用于场景理解和CAD模型对齐的大规模数据集。该数据集的目标是将真实场景的三维扫描与合成的CAD模型相关联。Scan2CAD 数据集包含了从Matterport3D\cite{chang2017matterport3d} 和 ScanNet\cite{dai2017scannet} 等公共数据集中的扫描数据，与来自ShapeNet等数据集的CAD模型。这些扫描和CAD模型之间的对应关系是通过专家注释来确定的。

Scan2CAD 数据集中的扫描数据包含了多种室内场景，如住宅、办公室和公共场所等。这些场景包括了各种物体，如家具、装饰品和建筑元素。与此同时，CAD模型包含了各种详细的几何和拓扑结构。部分可视化结果如图\ref{fig:ShapeNet&Scan2CAD} (b) 所示。

\subsection{多实例点云配准仿真数据集}
数据集：我们在合成数据集和真实数据集上进行实验。我们的合成数据集是从ModelNet40构建的，它包括来自40个类别的12311个网格化CAD模型。为了构建我们的合成数据集，对于每个模型，我们从中均匀地下采样1024个点以形成源点云，然后将其旋转和平移5-10次以生成多个实例。这些实例与噪声点混合，形成如图3所示的目标点云。沿每个轴的旋转在[0,180°]内均匀采样，平移在[0,5]内。我们为合成数据集生成的输入对应关系是通过将真实对应关系与异常值混合而生成的。我们将每个实例的内点比率控制在约2\%。我们使用12311个模型生成了12311个这样的合成源-目标点云对。我们使用9843对进行训练，2468对进行测试。我们在训练集中随机留出10\%的对作为验证集。

\subsection{多实例点云配准真实数据集}
我们的真实数据集是 Scan2CAD ，它利用 ShapeNet 和 ScanNet 构建而成。此数据集使用 ShapeNet 中的 CAD 模型替换真实扫描场景中的点云，并提供精确的注释，包括模型类别、旋转和平移等。数据集提供了 1506 个带注释的场景，每个场景至少包含一个实例类别。因此，我们充分利用这些注释，并将包含多种实例的场景分割成多个源-目标点云对，用于多实例注册。通过这种方式，我们得到了 2184 对点云，其中大多数点云在目标点云中包含 2-5 个相同类别的实例。我们按照 7:1:2 的比例将样本划分为训练集、验证集和测试集。我们使用微调的 FCGF\cite{FCGF2019} 生成局部特征并通过特征匹配生成假设的对应关系。
\begin{table}[h]
    \centering
    \vspace{-1.0cm}
    \begin{minipage}{0.45\textwidth}
        \centering
        \caption{FCGF 网络参数设置和预训练}
        \label{tab:fcgf}
        \begin{tabular}{cc}
        \toprule
        \multicolumn{2}{c}{FCGF 网络参数设置和预训练} \\ 
        \midrule
        模型                 & RESUNETBN2C      \\ 
        下采样体素大小          & 2.5cm (0.025)    \\ 
        特征维度                & 32               \\ 
        预训练数据集             & 3DMatch          \\ 
        特征归一化              & 是               \\ 
        \bottomrule
        \end{tabular}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \caption{FCGF 网络微调参数设置}
        \label{tab:fcgf_finetune}
        \begin{tabular}{cc}
        \toprule
        \multicolumn{2}{c}{FCGF 网络微调参数设置} \\ 
        \midrule
        批量大小               & 4                 \\ 
        学习率                 & $10^{-3}$         \\ 
        迭代次数                & 20                \\ 
        优化器                 & SGD               \\ 
        \bottomrule
        \end{tabular}
    \end{minipage}
    \vspace{-1.0cm}
\end{table}

这里，我们主要关注如何通过特征匹配生成假设的对应关系。我们使用 FCGF 作为特征提取器，参数设置如表 \ref{tab:fcgf} 所示。FCGF 网络在 3DMatch 数据集上预训练，然后使用表 \ref{tab:fcgf_finetune} 中的参数设置进行微调。微调过的 FCGF 提取 L2归一化的局部特征 $F_{local}^X = \{f_{local}^{x_i} \in \mathbb{R}^{32} | i = 1, \dots, |X|\}$，用于源点云 $X$ 和 $F_{local}^Y = \{f_{local}^{y_i} \in \mathbb{R}^{32} | i = 1, \dots, |Y|\}$，用于目标点云 $Y$，其中 $|X|$ 和 $|Y|$ 分别表示源点云和目标点云中的点数。给定目标点云 $Y$ 中的每个点 $y_j$，我们找到满足 $i = \arg\max_i \langle f_{local}^{y_j}, f_{local}^{x_i} \rangle$ 的源点云 $X$ 中的点 $x_i$ 以构建对应关系 $(x_i, y_j)$，其中 $\langle f_{local}^{y_j}, f_{local}^{x_i} \rangle$ 是两点特征之间的余弦相似度。这样，我们获得 $|Y|$ 个对应关系，我们将余弦相似度 $\langle f_{local}^{x_i}, f_{local}^{y_j} \rangle$ 定义为对应关系 $(x_i, y_j)$ 的显著性得分。我们选择显著性得分最大的 $K$ 个对应关系，然后将这些 $K$ 个对应关系随机下采样为 $N$ 个对应关系作为输入的假设对应关系。这里，我们将 $K$ 设置为 10000，以使输入对应关系尽可能覆盖更多实例。
\section{点云配准评价指标}
对于配准任务，评估指标可以主要分为两类，一类是用于特征提取与匹配的评价指标，另一类是用于配准结果运动参数评价的指标。
\subsection{基于特征提取与匹配的评价指标}
\subsubsection{特征匹配召回率 (Feature Matching Recall)}
特征匹配召回率衡量了匹配算法在正确提取匹配点对数量和所有点对数量之间的比率，反映了匹配算法的查全率。从数学角度来看，特征匹配召回率可以表示为：
\begin{equation}
R_{fa} = \frac{1}{n} \sum_{s=1}^{n} \mathbbm{1} \left( \frac{1}{|\boldsymbol{\omega}|} \sum_{(\boldsymbol{i},\boldsymbol{j})\in\boldsymbol{\omega}} (\lVert \boldsymbol{T}\boldsymbol{p}_i - \boldsymbol{q}_j \rVert < \tau_1) > \tau_2 \right)
\end{equation}
其中 $n$ 是所有点对的数量，$\boldsymbol{\omega}$ 是匹配点对 $(\boldsymbol{p}, \boldsymbol{q})$ 之间的对应关系集合，$\boldsymbol{p} = (x_p, y_p, z_p)$，$\boldsymbol{q} = (x_q, y_q, z_q)$，$\boldsymbol{T} \in SE(3)$ 是地面真实姿态变换矩阵。此外，$\tau_1$ 是内部距离阈值，$\tau_2$ 是内部召回率阈值。
\subsubsection{点云配准召回率 (Point Cloud Registration Recall)}
配准召回率衡量了在具有地面真实姿态变换且存在重叠部分的两组点云中，有多少重叠部分的点云组可以通过匹配算法被正确恢复。具体而言，配准召回率使用如下误差矩阵来定义真阳性：
\begin{equation}
    E = \sqrt{\frac{1}{|\boldsymbol{\omega}^*|} \sum_{(\boldsymbol{p}^*,\boldsymbol{q}^*)\in\boldsymbol{\omega}^*} \lVert \boldsymbol{\hat{T}}_{i,j}\boldsymbol{p}^* - \boldsymbol{q}^* \rVert^2} < \tau_3
\end{equation}
    
其中，$\boldsymbol{\omega}^*$ 是重叠部分一组匹配点对 $(\boldsymbol{p}^*, \boldsymbol{q}^*)$ 之间的对应关系集合，$\boldsymbol{p}^* = (x^*_p, y^*_p, z^*_p)$，$\boldsymbol{q}^* = (x^*_q, y^*_q, z^*_q)$。对于重叠部分，$\tau_3$ 是用于判断匹配点对是否正确的阈值。

\subsection{基于刚体运动的评价指标}
\subsubsection{投影的均方根误差}
投影的均方根误差 (RMSE Projection) 是在应用变换之后，计算点到点投影误差的平均值。计算公式为：
\begin{equation}
    \text{RMSE} (\boldsymbol{p}) = \frac{1}{n}\sum_{i=1}^{n} \sqrt{(\boldsymbol{p}_i^{'} - \boldsymbol{p}_i)^2},
\end{equation}
其中 $n$ 是点云中的点数，$\boldsymbol{p}_i^{'}$ 是应用变换后的点，$\boldsymbol{p}_i$ 是原始点。

\subsubsection{变换的均方根误差}
变换的均方根误差 (RMSE Tranformation) 代表估计的变换 $\boldsymbol{\hat{T}}_{s}$ 和真实变换 $\boldsymbol{T}^*_{s}$ 之间的均方根误差。计算公式为：
\begin{equation}
    \text{RMSE} (\boldsymbol{T}) = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(\boldsymbol{\hat{T}}_{s} - \boldsymbol{T}^*_{s})^2},
\end{equation}

\subsubsection{相对旋转误差}
我们定义相对旋转误差 (Relative Rotation Error) 为真实变换 $\boldsymbol{T}^*_{s}$ 和估计变换 $\boldsymbol{\hat{T}}_{s}$ 之间的旋转误差。计算公式为：
\begin{equation}
    \text{RRE}_s = \arccos \left(\frac{\operatorname{tr}(\boldsymbol{\hat{R}}_{s} \boldsymbol{R}^*_s) - 1}{2}\right),
\end{equation}
其中 $\operatorname{tr}$ 表示矩阵的迹（对角线元素之和），$\boldsymbol{\hat{R}}_{s}$ 和 $\boldsymbol{R}^*_s$ 分别表示估计变换和真实变换的旋转矩阵。

\subsubsection{相对平移误差}
我们定义相对平移误差 (Relative Transition Error) 为真实变换 $\boldsymbol{T}^*_s$ 和估计变换 $\boldsymbol{\hat{T}}_{s}$ 之间的平移误差。计算公式为：
\begin{equation}
    \text{RTE}_s = \lVert \boldsymbol{t}^*_s - \boldsymbol{\hat{t}}_{s} \rVert,
\end{equation}
其中 $\boldsymbol{t}^*_s$ 和 $\boldsymbol{\hat{t}}_{s}$ 分别表示真实变换和估计变换的平移向量。

\subsection{多实例点云配准评价指标}
用于评估多实例点云配准性能的三个指标分别是平均命中召回率、平均命中精度和平均命中 F1 分数。这三个评估指标是基于

\subsubsection{平均命中召回率 (Mean Hit Recall)}
平均命中召回率衡量了正确恢复的点云对数占所有点云对数的比例。平均命中召回率 (Mean Hit Recall) 在两个已配准的点云之间的定义如下：
\begin{equation}
    \text{MHR} = \frac{1}{\boldsymbol{K}} \sum_{s=1}^{S} \boldsymbol{I}_s
\end{equation}
其中 $\boldsymbol{I}_s = {0, 1}$ 表示一个真实估计对是否为“命中”。具体而言，
\begin{equation}
    \boldsymbol{I}_s = \boldsymbol{I}(\text{RRE}_s < \tau_r) \times \boldsymbol{I}(\text{RTE}_s < \tau_t)
\end{equation}
其中 $\boldsymbol{I}(\cdot) = {0, 1}$ 表示一个指示函数。$\text{RRE}_s$ 和 $\text{RTE}_s$ 是第 $s$ 个真实估计对的相对旋转误差和相对平移误差。两个阈值 $\boldsymbol{\tau_r}$ 和 $\boldsymbol{\tau_t}$ 分别设置为 $20^\circ$ 和 $0.5m$。通过对所有点云对的 \text{MHR} 求平均值，得到最终的平均命中召回率。

\subsubsection{平均命中精确度 (\text{Mean Hit Precision})}
两个已配准的点云之间的平均命中精确度定义如下：

\begin{equation}
\text{MHP} = \frac{1}{\boldsymbol{M}} \sum_{s=1}^{S} \boldsymbol{I}_s
\end{equation}
通过对所有点云对的 \text{MHP} 求平均值，得到最终的平均命中精确度。

\subsubsection{平均命中 F1 (\text{Mean Hit F1})}
两个已配准的点云之间的平均命中 F1 定义如下：
\begin{equation}
\text{MHF1} = \frac{2 \times \text{MHP} \times \text{MHR}}{\text{MHP} + \text{MHR}}
\end{equation}
通过对所有点云对的 \text{MHF1} 求平均值，得到最终的平均命中 F1。


\section{点云处理与配准相关深度学习技术}

\subsection{深度学习概述}
在过去的十年中，深度学习在计算机视觉、自然语言处理等各个领域取得了重要进展 \cite{lecun2015deep}。随着激光雷达、RGB-D 相机和其他三维扫描设备获取的 3D 数据日益增多，深度学习技术逐渐应用于点云处理任务，包括点云配准 \cite{wang2019dynamic, choy2020deep}。点云配准是 3D 计算机视觉中的一个基本问题，目的是找到将两个点云精确对齐的最优变换。

近年来，针对点云配准的深度学习方法已经在自动学习区分性特征和从大规模数据集中学习鲁棒匹配策略方面展示出优于传统方法的性能 \cite{huang2022multiway, lu2019deepvcp}。这些方法利用各种类型的网络架构，例如 PointNet \cite{qi2017pointnet}、PointNet++ \cite{qi2017pointnet++} 和 DGCNN \cite{wang2019dynamic}，有效地处理点云数据的非结构化和无序特性。

训练深度神经网络涉及使用反向传播算法，该算法通过应用链式法则计算损失函数相对于每个权重的梯度。使用基于梯度的优化方法（如随机梯度下降（SGD）、Adam\cite{kingma2014adam} 或 MoCo\cite{he2020momentum}）更新权重。为了防止过拟合，采用了如 dropout 等正则化技术，即在训练过程中随机将一层中的一部分神经元设置为零。这种策略迫使网络学习更鲁棒的特征，提高了对未见数据的泛化能力。

\begin{equation}
    L(\boldsymbol{W}) = \frac{1}{N} \sum_{i=1}^{N} L_i(\boldsymbol{W}) + \lambda \sum_{l=1}^{L} \lVert \boldsymbol{W}^{(l)} \rVert^2
\end{equation}

在上述方程中，$L(\boldsymbol{W})$ 表示总损失，$L_i(\boldsymbol{W})$ 表示第 $i^{th}$ 个样本的损失，$\boldsymbol{W}^{(l)}$ 表示第 $l$ 层的权重，$L$ 是总层数，$\lambda$ 是正则化参数，$\lVert \cdot \rVert^2$ 表示平方 Frobenius 范数。

为了方便设计、训练和部署深度学习模型，开发了几种深度学习框架，包括TensorFlow\cite{abadi2016tensorflow}、PyTorch\cite{paszke2019pytorch}、PaddlePaddle\cite{ma2019paddlepaddle} 和 MXNet\cite{chen2015mxnet}。这些框架提供了神经网络层、优化算法和其他实用工具的高效实现，使设计、训练和部署深度学习模型变得更加容易。此外，它们还支持使用 GPU （torch.cuda）或专用加速器（如 TPU）进行硬件加速，以加快训练过程。
\subsection{多层感知机}
多层感知器（Multilayer Perceptron, MLP）是一种广泛应用于各种机器学习任务的前馈神经网络\cite{lecun2015deep}。MLP 的基本结构包括输入层、一个或多个隐藏层和输出层。每一层由若干个神经元组成，相邻层的神经元之间通过权重连接。通常，MLP 采用全连接结构，即每个神经元都与上一层和下一层的所有神经元连接。

在训练 MLP 时，需要先进行前向传播计算，即从输入层到输出层计算预测值。接下来，通过反向传播算法计算损失函数对权重的梯度。最后，使用梯度下降或其变体更新权重。

考虑一个简单的两层 MLP，其输入层有 $n$ 个神经元，输出层有 $m$ 个神经元。对于输入向量 $\boldsymbol{x} \in \mathbb{R}^{n}$ 和权重矩阵 $\boldsymbol{W} \in \mathbb{R}^{m \times n}$，MLP 的输出为：

\begin{equation}
\boldsymbol{y} = f(\boldsymbol{W}\boldsymbol{x} + \boldsymbol{b}),
\end{equation}

其中 $\boldsymbol{b} \in \mathbb{R}^{m}$ 是偏置向量，$f$ 是激活函数。在实际应用中，激活函数通常为非线性函数，如 Sigmoid、ReLU 或 Tanh。这些非线性激活函数使得 MLP 能够捕捉复杂的非线性关系。

现在我们考虑一个具有 $L$ 个隐藏层的 MLP，设第 $l$ 层的权重矩阵为 $\boldsymbol{W}^{(l)} \in \mathbb{R}^{n_l \times n_{l-1}}$，偏置向量为 $\boldsymbol{b}^{(l)} \in \mathbb{R}^{n_l}$，激活函数为 $f^{(l)}$。前向传播过程可表示为：

\begin{equation}
\boldsymbol{a}^{(l)} = f^{(l)}(\boldsymbol{W}^{(l)}\boldsymbol{a}^{(l-1)} + \boldsymbol{b}^{(l)}),
\end{equation}

其中 $\boldsymbol{a}^{(0)} = \boldsymbol{x}$，$\boldsymbol{a}^{(L)} = \boldsymbol{y}$。对于损失函数 $L(\boldsymbol{y}, \boldsymbol{t})$，其中 $\boldsymbol{t}$ 是目标输出，我们使用梯度下降方法优化权重和偏置：

\begin{equation}
\boldsymbol{W}^{(l)} \leftarrow \boldsymbol{W}^{(l)} - \alpha \frac{\partial L}{\partial \boldsymbol{W}^{(l)}}, \\
\end{equation}
\begin{equation}
\boldsymbol{b}^{(l)} \leftarrow \boldsymbol{b}^{(l)} - \alpha \frac{\partial L}{\partial \boldsymbol{b}^{(l)}},
\end{equation}

其中 $\alpha$ 是学习率。

为了计算梯度，我们使用反向传播算法。首先，计算输出层关于损失函数的梯度：

\begin{equation}
\boldsymbol{\delta}^{(L)} = \frac{\partial L}{\partial \boldsymbol{a}^{(L)}} \odot f'^{(L)}(\boldsymbol{W}^{(L)}\boldsymbol{a}^{(L-1)} + \boldsymbol{b}^{(L)}),
\end{equation}

其中 $\odot$ 表示哈达玛积（元素对应相乘），$f'^{(L)}$ 是激活函数的导数。

然后，我们从输出层向输入层反向计算梯度：

\begin{equation}
\boldsymbol{\delta}^{(l)} = \left( \boldsymbol{W}^{(l+1)} \right)^T \boldsymbol{\delta}^{(l+1)} \odot f'^{(l)}(\boldsymbol{W}^{(l)}\boldsymbol{a}^{(l-1)} + \boldsymbol{b}^{(l)}).
\end{equation}

最后，我们计算损失函数关于权重和偏置的梯度：

\begin{equation}
\frac{\partial L}{\partial \boldsymbol{W}^{(l)}} = \boldsymbol{\delta}^{(l)} \left( \boldsymbol{a}^{(l-1)} \right)^T, \\
\end{equation}
\begin{equation}
\frac{\partial L}{\partial \boldsymbol{b}^{(l)}} = \boldsymbol{\delta}^{(l)}.
\end{equation}

在实际应用中，为了提高训练速度和泛化能力，我们通常采用 mini-batch 随机梯度下降或其变体（如 Adam、RMSprop 等）进行训练。此外，我们还可以使用正则化技术（如 L1、L2正则化、Dropout 等）防止过拟合。在深度学习框架（如 TensorFlow、PyTorch、PaddlePaddle 和 MXNet 等）的支持下，我们可以方便地实现和训练 MLP 模型\cite{lecun2015deep}。

MLP 是深度学习领域的一个基本概念，尽管现在有许多更复杂的神经网络结构（如卷积神经网络、循环神经网络和 Transformer 等）已经在各种任务上表现出更好的性能，但 MLP 仍然是一个重要的基础知识。通过学习 MLP 的基本原理，我们可以更好地理解神经网络的工作原理，从而有助于设计更复杂的模型和解决更高级的问题。

在实际应用中，MLP 可以处理各种类型的数据，如图像、文本、语音和其他结构化或非结构化数据。由于 MLP 可以近似任意连续函数，因此具有很强的表达能力。然而，MLP 也存在一些局限性。首先，MLP 的参数数量随着层数和每层神经元数量的增加而快速增长，这可能导致过拟合和计算效率低下的问题。其次，MLP 对输入数据的缩放和平移具有较强的敏感性，因此需要对输入数据进行预处理，如归一化。此外，MLP 并不能直接处理变长输入数据和序列数据，需要采用其他神经网络结构，如循环神经网络（RNN）。

尽管如此，MLP 作为一种基础的神经网络结构，在许多任务中仍具有竞争力。例如，在监督学习任务中，MLP 可以用于分类和回归问题；在无监督学习任务中，MLP 可以用于降维和聚类。通过合适的设计和训练策略，MLP 能够在各种应用场景中实现良好的性能。

总之，多层感知器（MLP）是深度学习领域的一个基本概念，作为前馈神经网络的一种，它具有广泛的应用价值。MLP 主要包括输入层、隐藏层和输出层，通过前向传播、反向传播算法进行训练。
\subsection{卷积神经网络}
卷积神经网络（CNN）是一类在各种任务中取得显著成功的深度学习模型，尤其在图像识别、目标检测和自然语言处理等领域。CNN 旨在学习空间特征层次结构，使其特别适用于处理网格状数据（如图像），其中局部依赖关系至关重要\cite{chua1993cnn}。

CNN 的基本构建模块是卷积层。在这个层中，小滤波器（也称为内核）应用于输入，计算滤波器和输入之间的局部点积。这个操作生成一个特征映射，对输入和滤波器之间的空间关系进行编码\cite{he2016deep}。滤波器权重在训练过程中学习，使网络能够自动学习任务特定特征。

从数学上讲，CNN 中的卷积运算可以描述为以下形式：

\begin{equation}
  y_{i,j} = \sum_{m} \sum_{n} x_{i-m, j-n} \cdot w_{m,n},
\end{equation}

其中 $x$ 是输入，$w$ 是滤波器，$y$ 是输出特征映射，$i$、$j$、$m$ 和 $n$ 是输入和滤波器的空间维度对应的索引。

CNN 的一个关键方面是在整个输入中使用共享权重。这种参数共享显著减少了可训练参数的数量，使模型比全连接网络更具计算效率且不容易过拟合。此外，它使网络能够学习平移不变特征，因为相同的滤波器应用于输入的不同空间位置。

CNN 中的另一个重要组件是池化层，用于减少特征映射的空间尺寸。池化层通常在一个或多个卷积层之后应用，以实现局部平移不变性并减少网络的计算复杂性。有不同类型的池化操作，如最大池化、平均池化和全局池化。最大池化是最常用的池化方法，可以定义为：

\begin{equation}
  z_{i,j} = \max_{m,n \in P} x_{i+m, j+n},
\end{equation}

其中 $x$ 是输入特征映射，$z$ 是池化后的输出，$P$ 是池化窗口，$i$、$j$、$m$ 和 $n$ 是输入和池化窗口的空间维度对应的索引。

除了卷积和池化层之外，CNN 通常包括一个或多个全连接层，对学习到的特征进行高级推理。最后一个全连接层的输出通常通过 softmax 激活函数传递，以生成任务特定类别的概率。整个网络使用反向传播和基于梯度的优化算法（如随机梯度下降或 Adam）进行训练。

CNN 已成功应用于广泛的任务，包括图像分类、目标检测、语义分割和自然语言处理。CNN 的成功可以归因于其学习输入数据的分层表示、共享权重和平移不变特征的能力。此外，通过修改其架构和损失函数，CNN 可以轻松地适应不同的任务\cite{albawi2017understanding}。

\subsection{注意力机制}
注意力机制已经成为深度学习模型的重要组成部分，特别是在计算机视觉和点云处理任务中。注意力机制的核心概念是让模型在处理输入数据时，根据上下文信息有选择地关注不同部分，从而提高性能和可解释性。

在计算机视觉领域，注意力机制可以帮助模型更有效地识别和关注图像中的重要区域，以实现更准确的对象识别、语义分割和目标检测。在点云处理任务中，注意力机制可以帮助模型学习点云中的局部和全局结构特征，从而在点云配准、点云分割和分类任务中实现更高的性能。

数学上，注意力机制可以通过以下方式进行描述：

\begin{equation}
\text{Attention}(\boldsymbol{Q}, \boldsymbol{K}, \boldsymbol{V}) = \text{softmax}(\frac{\boldsymbol{Q}\boldsymbol{K}^\top}{\sqrt{d_k}})\boldsymbol{V},
\end{equation}

其中 $\boldsymbol{Q}$、$\boldsymbol{K}$ 和 $\boldsymbol{V}$ 分别表示查询（Query）、键（Key）和值（Value）矩阵，$d_k$ 是键和查询向量的维度。这个计算过程可以解释为：查询向量与键向量的点积表示它们之间的相似性，通过应用 softmax 函数将这些相似性归一化为概率分布，然后使用这些概率分布加权值向量，得到最终的输出。

在计算机视觉和点云处理任务中，注意力机制通常与卷积神经网络（CNN）或图神经网络（GNN）结合使用，以捕获局部和全局上下文信息。这些组合模型在大量基准数据集上表现出卓越的性能，证明了注意力机制在这些领域的有效性。


\section{基于深度学习的点云配准方法}
\subsection{PointNet \& PointNet++}
\subsection{Predator}
\subsection{TEASER}